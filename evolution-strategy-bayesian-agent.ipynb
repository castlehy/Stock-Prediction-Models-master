{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from bayes_opt import BayesianOptimization\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesianOptimization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(data, t, n):\n",
    "    d = t - n + 1\n",
    "    block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1]\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(block[i + 1] - block[i])\n",
    "    return np.array([res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xx1z.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('USDT-BTC.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"Open\"] = df[\"Open\"] / df[\"Open\"].max()\n",
    "#df[\"High\"] = df[\"High\"] / df[\"High\"].max()\n",
    "#df[\"Low\"]  = df[\"Low\"] / df[\"Low\"].max()\n",
    "#df[\"Close\"] = df[\"Close\"] / df[\"Close\"].max()\n",
    "#df[\"Adj Close\"] = df[\"Adj Close\"] / df[\"Adj Close\"].max()\n",
    "#df[\"Volume\"] = df[\"Volume\"] / df[\"Volume\"].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Close\"] = df[\"Close\"] /1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = df.Close.values.tolist()\n",
    "window_size = 30\n",
    "skip = 5\n",
    "l = len(close) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Evolution_Strategy:\n",
    "\n",
    "    inputs = None\n",
    "\n",
    "    def __init__(self, weights, reward_function, population_size, sigma, learning_rate):\n",
    "        self.weights = weights\n",
    "        self.reward_function = reward_function\n",
    "        self.population_size = population_size\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _get_weight_from_population(self, weights, population):\n",
    "        weights_population = []\n",
    "        for index, i in enumerate(population):\n",
    "            jittered = self.sigma * i\n",
    "            weights_population.append(weights[index] + jittered)\n",
    "        return weights_population\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def train(self, epoch = 100, print_every = 1):\n",
    "        lasttime = time.time()\n",
    "        for i in range(epoch):\n",
    "            population = []\n",
    "            rewards = np.zeros(self.population_size)\n",
    "            for k in range(self.population_size):\n",
    "                x = []\n",
    "                for w in self.weights:\n",
    "                    x.append(np.random.randn(*w.shape))\n",
    "                population.append(x)\n",
    "            for k in range(self.population_size):\n",
    "                weights_population = self._get_weight_from_population(self.weights, population[k])\n",
    "                rewards[k] = self.reward_function(weights_population)\n",
    "            rewards = (rewards - np.mean(rewards)) / np.std(rewards)\n",
    "            for index, w in enumerate(self.weights):\n",
    "                A = np.array([p[index] for p in population])\n",
    "                self.weights[index] = w + self.learning_rate/(self.population_size * self.sigma) * np.dot(A.T, rewards).T\n",
    "            if (i+1) % print_every == 0:\n",
    "                print('iter %d. reward: %f' %  (i+1, self.reward_function(self.weights)))\n",
    "        print('time taken to train:', time.time()-lasttime, 'seconds')\n",
    "        \n",
    "class Model:\n",
    "    def __init__(self, input_size, layer_size, output_size):\n",
    "        self.weights = [np.random.randn(input_size, layer_size), \n",
    "                        np.random.randn(layer_size, output_size),\n",
    "                        np.random.randn(layer_size, 1),\n",
    "                        np.random.randn(1, layer_size)]\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        feed = np.dot(inputs, self.weights[0]) + self.weights[-1]\n",
    "        decision = np.dot(feed, self.weights[1])\n",
    "        buy = np.dot(feed, self.weights[2])\n",
    "        return decision, buy\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, population_size, sigma, learning_rate, model, money, max_buy, max_sell, skip, window_size):\n",
    "        self.window_size = window_size\n",
    "        self.skip = skip\n",
    "        self.POPULATION_SIZE = population_size\n",
    "        self.SIGMA = sigma\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.model = model\n",
    "        self.initial_money = money\n",
    "        self.max_buy = max_buy\n",
    "        self.max_sell = max_sell\n",
    "        self.es = Deep_Evolution_Strategy(self.model.get_weights(), self.get_reward, self.POPULATION_SIZE, self.SIGMA, self.LEARNING_RATE)\n",
    "    \n",
    "    def act(self, sequence):\n",
    "        decision, buy = self.model.predict(np.array(sequence))\n",
    "        return np.argmax(decision[0]), int(buy[0])\n",
    "    \n",
    "    def get_reward(self, weights):\n",
    "        initial_money = self.initial_money\n",
    "        starting_money = initial_money\n",
    "        self.model.weights = weights\n",
    "        state = get_state(close, 0, self.window_size + 1)\n",
    "        inventory = []\n",
    "        quantity = 0\n",
    "        for t in range(0,l,self.skip):\n",
    "            action, buy = self.act(state)\n",
    "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
    "            if action == 1 and initial_money >= close[t]:\n",
    "                if buy < 0:\n",
    "                    buy = 1\n",
    "                if buy > self.max_buy:\n",
    "                    buy_units = self.max_buy\n",
    "                else:\n",
    "                    buy_units = buy\n",
    "                total_buy = buy_units * close[t]\n",
    "                initial_money -= total_buy\n",
    "                inventory.append(total_buy)\n",
    "                quantity += buy_units\n",
    "            elif action == 2 and len(inventory) > 0:\n",
    "                if quantity > self.max_sell:\n",
    "                    sell_units = self.max_sell\n",
    "                else:\n",
    "                    sell_units = quantity\n",
    "                quantity -= sell_units\n",
    "                total_sell = sell_units * close[t]\n",
    "                initial_money += total_sell\n",
    "                \n",
    "            state = next_state\n",
    "        return ((initial_money - starting_money) / starting_money) * 100\n",
    "    \n",
    "    def fit(self, iterations, checkpoint):\n",
    "        self.es.train(iterations,print_every=checkpoint)\n",
    "        \n",
    "    def buy(self):\n",
    "        initial_money = self.initial_money\n",
    "        state = get_state(close, 0, self.window_size + 1)\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        quantity = 0\n",
    "        for t in range(0,l,self.skip):\n",
    "            action, buy = self.act(state)\n",
    "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
    "            if action == 1 and initial_money >= close[t]:\n",
    "                if buy < 0:\n",
    "                    buy = 1\n",
    "                if buy > self.max_buy:\n",
    "                    buy_units = self.max_buy\n",
    "                else:\n",
    "                    buy_units = buy\n",
    "                total_buy = buy_units * close[t]\n",
    "                initial_money -= total_buy\n",
    "                inventory.append(total_buy)\n",
    "                quantity += buy_units\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy %d units at price %f, total balance %f'%(t,buy_units, total_buy,initial_money))\n",
    "            elif action == 2 and len(inventory) > 0:\n",
    "                bought_price = inventory.pop(0)\n",
    "                if quantity > self.max_sell:\n",
    "                    sell_units = self.max_sell\n",
    "                else:\n",
    "                    sell_units = quantity\n",
    "                if sell_units < 1:\n",
    "                    continue\n",
    "                quantity -= sell_units\n",
    "                total_sell = sell_units * close[t]\n",
    "                initial_money += total_sell\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((total_sell - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print('day %d, sell %d units at price %f, investment %f %%, total balance %f,'%(t, sell_units, total_sell, invest, initial_money))\n",
    "            state = next_state\n",
    "        \n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        print('\\ntotal gained %f, total investment %f %%'%(initial_money - starting_money,invest))\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.plot(close, label='true close',c='g')\n",
    "        plt.plot(close, 'X', label='predict buy',markevery=states_buy, c='b')\n",
    "        plt.plot(close, 'o', label='predict sell',markevery=states_sell,c='r')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_agent(window_size, skip, population_size, sigma, learning_rate, size_network):\n",
    "    model = Model(window_size, size_network, 3)\n",
    "    agent = Agent(population_size, sigma, learning_rate,model,10000,5,5,skip,window_size)\n",
    "    try:\n",
    "        agent.fit(10, 1000)\n",
    "        return agent.es.reward_function(agent.es.weights)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_agent(window_size, skip, population_size, sigma, learning_rate, size_network):\n",
    "    global accbest\n",
    "    param = {\n",
    "        'window_size' : int(np.around(window_size)),\n",
    "        'skip' : int(np.around(skip)),\n",
    "        'population_size' : int(np.around(population_size)),\n",
    "        'sigma' : max(min(sigma, 1), 0.0001),\n",
    "        'learning_rate' : max(min(learning_rate, 0.5), 0.000001),\n",
    "        'size_network': int(np.around(size_network))\n",
    "    }\n",
    "    print(\"\\nSearch parameters %s\" % (param))\n",
    "    investment = best_agent(**param)\n",
    "    print(\"stop after 100 iteration with investment %f\" % (investment))\n",
    "    if (investment > accbest):\n",
    "        costbest = investment\n",
    "    return investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accbest = 0.0\n",
    "NN_BAYESIAN = BayesianOptimization(find_best_agent, \n",
    "                              {'window_size': (2, 50),\n",
    "                               'skip': (1, 15),\n",
    "                               'population_size': (1, 50),\n",
    "                               'sigma': (0.01, 0.45),\n",
    "                               'learning_rate': (0.000001, 0.4),\n",
    "                               'size_network': (10,1000)\n",
    "                              })\n",
    "NN_BAYESIAN.maximize(init_points = 30, n_iter = 50, acq = 'ei', xi = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_BAYESIAN.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best AGENT accuracy value: %f' % NN_BAYESIAN.res['max']['max_val'])\n",
    "print('Best AGENT parameters: ', NN_BAYESIAN.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my parameter\n",
    "best_agent(30,1,15,0.1,0.03,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from bayesian\n",
    "best_agent( 32,0.4325,36 , 0.3034,0.2780 , 232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size, skip, population_size, sigma, learning_rate, size_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Value |   learning_rate |   population_size |     sigma |   size_network |      skip |   window_size | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 27.43191 |          0.2780 |           36.3093 |    0.3034 |       232.2999 |    1.4325 |       32.3889 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my parameter\n",
    "model = Model(30, 500, 3)\n",
    "agent = Agent(15, 0.1, 0.03,model,10000,5,5,1,30)\n",
    "agent.fit(500, 100)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(30, 500, 3)\n",
    "agent = Agent(36, 0.3034, 0.2780,model,10000,20,20,1,30)\n",
    "agent.fit(500, 100)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from bayesian\n",
    "model = Model(20, 176, 3)\n",
    "agent = Agent(34, 0.7152490670931403, 0.28208006704411104,model,10000,5,5,1,20)\n",
    "agent.fit(500, 100)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(30, 500, 3)\n",
    "agent = Agent(36, 0.3034, 0.2780,model,10000,20,20,1,30)\n",
    "#agent.fit(50, 10)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(30, 500, 3)\n",
    "agent = Agent(36, 0.3034, 0.2780,model,10000,20,20,1,30)\n",
    "agent.fit(1, 1)\n",
    "agent.buy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
